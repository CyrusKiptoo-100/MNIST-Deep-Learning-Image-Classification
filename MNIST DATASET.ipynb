{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOrXVytL0ZFqlufMljUe0oL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Given a MNIST dataset containing 70,000 28x28 grsyscale images of handwriting digits (0-9).\n","it is a benchmak dataset for image classification tasks in the field of machine learning\n","  *Classes 10\n","  *Trainingset 60,000 images\n","  *Test Set 10,000 images\n"],"metadata":{"id":"aSEfEOQFtrv_"}},{"cell_type":"markdown","source":["TASK\n","Create a CNN Model using this dataset and finetune it to get above 70% accuracy"],"metadata":{"id":"L_xT9Ot2ydM-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FK8O-7dBtlJk"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten,Dense,Dropout\n","from tensorflow.keras.datasets import fashion_mnist\n","from keras.utils import to_categorical"]},{"cell_type":"code","source":["#loading and splitting dataset\n","(X_train,y_train),(X_test,y_test)=fashion_mnist.load_data()"],"metadata":{"id":"1DHXF1ItzkWe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Normalize the images to the range of 0 to 1\n","x_train=X_train.astype('float32')/255.0\n","x_test=X_test.astype('float32')/255. #X_train to float32. This is necessary for numerical computations in TensorFlow.\n","\n","#255. divides each pixel value by 255. This operation scales the pixel values down to a range between 0 and 1.\n","#Normalizing pixels values helps to improve performance and stability of neural netwoks during trainng\n"],"metadata":{"id":"spkWTiwl0D8Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# One-Hot encode the labels\n","y_train=to_categorical(y_train,10)\n","y_test=to_categorical(y_test,10)\n","#By one-hot Encode the labels ,you prepare the target data for training the neural network,\n","#Allowing it to effectively learn to classify the different categories.\n","#Neural networks learn from numerical values only"],"metadata":{"id":"Gby3CbwW1SD8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MODEL BUILDING\n"],"metadata":{"id":"lJhTsowb5Gxw"}},{"cell_type":"code","source":["#Build model\n","model=Sequential()\n","#This code initiates a sequential model in keras.\n","#the sequential class allows you to create a linear stack of layers\n","#where you can add layer one by one to build your neural architecture\n","#In essence, this line sets up the foundation for constructing your model by creating an empty container to which you will subsequently add the desired layers"],"metadata":{"id":"UwN5xWr-5D4u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Convolution Layer 1\n","model.add(Conv2D(32, (3, 3),activation='relu',input_shape=(28,28,1)))\n","#32-Number of filters that passes through the inputs to learn features from it.\n","#(3,3) the size of filters\n","#activation relu a function of output ,intrduces non_linearity to the model to allow it to learn from complex patterns.\n","model.add(MaxPooling2D((2, 2)))#This helps in downsampling the data to reduce the number of parameters and computation"],"metadata":{"id":"WIjOmR_b51TS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Convolution Layer 2\n","model.add(Conv2D(64, (3, 3),activation='relu'))\n","model.add(MaxPooling2D((2,2)))"],"metadata":{"id":"QN5K-Br_7QUc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Convolution Layer 3\n","model.add(Conv2D(64, (3, 3),activation='relu'))\n"],"metadata":{"id":"pyZd_3Iw7W8B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Flattening the results to feed into the dense layer\n","model.add(Flatten())"],"metadata":{"id":"YeXrZWJs7sMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.add(Dense(64,activation='relu'))\n","model.add(Dropout(0.5))#Dropout for regulization preventing over fitting and improves the model generalization ability\n","model.add(Dense(10,activation='softmax'))#Output layers with 10 neurons\n","#The softmax activation function converts the raw data into probabilities, ensuring that the sum of all probabilities equals 1.\n"],"metadata":{"id":"NegSN0oj72Ys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Compiling the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',#measures the difference between predicted probabilities and true values\n","              metrics=['accuracy'])\n","#Adam optimizerfor updating model weights during training and testing to minimize loss function\n"],"metadata":{"id":"QmA4kat18wsc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training The Model"],"metadata":{"id":"veEoOtlH-VfD"}},{"cell_type":"code","source":["#training the model\n","model.fit(x_train,y_train,epoch=10,batch_size=64,validation_split=0.2)"],"metadata":{"id":"FiVsQMU-BKFj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"K8fmc_O6Bbbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make predictions\n","predictions = model.predict(x_test)\n","\n","# Show a few predictions\n","import numpy as np\n","\n","for i in range(5):\n","    print(f'Prediction: {np.argmax(predictions[i])}, Actual: {np.argmax(y_test[i])}')"],"metadata":{"id":"1ORA06gfCi_a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gNOYgUkKCi8Q"},"execution_count":null,"outputs":[]}]}